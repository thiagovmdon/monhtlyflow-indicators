{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0edc9e0",
   "metadata": {},
   "source": [
    "### Code used for reading and converting PCraster files to array\n",
    "\n",
    "\n",
    "#### This code provide an automatic read of PCraster files into array, and then organize the data in a time series to be used for further analysis.\n",
    "\n",
    "#### The code will read a total of Z .map files, and will reshape each file from a (X, Y) to a (1, X * Y), and will assing each file matrix to a different line. Therefore we will have a time-series matrix of (Z, X * Y) shape. \n",
    "\n",
    "#### Since the full raster matrix is too big, a clone map mask is used to convert just the grids that are from rivers and streams in the map, reducing the number of columns. \n",
    "\n",
    "Developed by: Thiago Victor Medeiros do Nascimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcb4e3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pcraster import *\n",
    "import numpy as np\n",
    "from osgeo import gdal, gdalconst\n",
    "from osgeo import gdal_array\n",
    "from osgeo import osr\n",
    "import matplotlib.pylab as plt\n",
    "import subprocess\n",
    "import glob,os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "802313b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path =r'D:\\pythonDATA\\AquadaptTemez\\rastermapaccum'\n",
    "filenames = glob.glob(path + \"/*.map\")\n",
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0942f74f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48694800"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time series matrix \n",
    "mapfile = filenames[0]\n",
    "\n",
    "RasterLayer = gdal.Open(mapfile)\n",
    "\n",
    "ncols = RasterLayer.RasterXSize\n",
    "nrows = RasterLayer.RasterYSize\n",
    "\n",
    "# about 50 arrays\n",
    "numtotal = nrows*ncols\n",
    "numtotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "012e5efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We cannot process all the data efficiently, and besides we are interested mainly on data in the river cells, therefore we can \n",
    "# use a clone map with a filter. This map has 1 as river cells and 0 as non-river cells. Therefore, the processing will be optimizes\n",
    "# solely for the river cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c8482c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathfilter =r'C:\\Users\\User\\OneDrive\\IST\\RESEARCH\\python\\flowindicatorsmap\\rivernetworkabove5000mm2.map'\n",
    "mapfilter = readmap(pathfilter)\n",
    "Rastermapfilter = gdal.Open(pathfilter)\n",
    "mapfilterarray = pcr_as_numpy(mapfilter)\n",
    "mapfilterarray\n",
    "mapfilterarray[mapfilterarray < 1 ] = np.nan\n",
    "\n",
    "newnumtotal = np.count_nonzero(~np.isnan(mapfilterarray))\n",
    "\n",
    "# We need additionally to reshape our filter:\n",
    "mapfilterarrayres = np.reshape(mapfilterarray, (1, numtotal))\n",
    "mapfilterarrayres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e3438b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We reduce the field to perform the computation from: 48694800 to 2477898\n"
     ]
    }
   ],
   "source": [
    "print(\"We initially had a total of:\", numtotal, \"cells, however only\", newnumtotal, \"refers indeed for river cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "10020314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create an array with the total number of non NaNs as columns and the total months as rows:\n",
    "runofftsarray = np.zeros((len(filenames),newnumtotal),dtype=np.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1918f37a",
   "metadata": {},
   "source": [
    "This loop will read each month (.map file) transform it in a array, and exctract solely the river cells data for our runofftsarray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2bfaefe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mapfile in filenames:\n",
    "\n",
    "    \n",
    "    namewithmap = os.path.basename(mapfile)\n",
    "    namemap = namewithmap.replace(\".map\", \"\")\n",
    "    namemap = namemap.replace(\"T\", \"\")\n",
    "    \n",
    "    # The files are not organized in order when they are read, therefore we will make a way to write each line in the correct line of the geral\n",
    "    namemapint = int(namemap) - 1 \n",
    "    \n",
    "    mapread = readmap(mapfile)\n",
    "    mapreadarray = pcr_as_numpy(mapread)\n",
    "    mapreadarrayres = np.reshape(mapreadarray, (1, numtotal))\n",
    "    \n",
    "    \n",
    "    \n",
    "    runofftsarray[namemapint,:] = mapreadarrayres[~np.isnan(mapfilterarrayres)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0a7c34",
   "metadata": {},
   "source": [
    "Finally, the time-series matrix is saved as a CSV file to be further analysed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc99e052",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('D:\\pythonDATA\\AquadaptTemez\\runofftsarray.csv', runofftsarray, delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
